<p align="center">
  <img src="./概念図.png" alt="ComfyUI Proxy 概念図" width="720">
</p>

# GPUベース生成AI・CGアプリケーション向け統合実行基盤の概要

## 1. システムのコンセプト

本システムは、大規模なクラウドシステムでなく、特に **比較的小規模なAI利用企業・制作スタジオなど** において、複数台の高度なGPUサーバー群を **「ひとつのサービス」に見せ、自在に運用できるために新規に設計された仮想GPUゲートウェイシステム** です。フロント側からは「1台の高性能サーバー」に対してAPIを送っているように見える一方、バックエンドでは様々な実行環境にある複数ノードに自動で振り分けを行い統合、協調して動作する事で **低い導入・運用コストで高効率・高機能なこれからのAIシステムに必須な機能を実現** しています。

このシステムは現在 **ComfyUI を中心ターゲットで利用を想定・開発** していますが、GPUを使う汎用のシステムとして、以下のような各種 GPU ワークロードへ即時に展開可能です。

**- 画像・動画生成AI**

**- 高度な LLM 推論サーバー**

**- 3D/CG レンダリング**

**- 物理シミュレーション、量子化学計算など**

## 2. ビジネス的な特徴・メリット

### (1) 「1つのサービス」に見えるシンプルな利用体験
- クライアントシステムは単一のエンドポイントだけを意識すればよく、ノード数を気にする必要がありません。
- フロントエンドのコード変更なし（または最小限）でGPU ノードをいつでも追加し自由にスケールアウト可能です。

### (2) ComfyUI 以外にも適用可能な「共通GPU基盤」
- LLM サーバー、動画生成パイプライン、3DCGレンダリングなど HTTP ベースのGPUサービスで自由に利用できます。
- 「サービスごとにインフラを分ける」のではなく、1つの共通基盤に複数サービスを載せるモデルを実現。

### (3) スモールスタートからの段階的スケールアウト
- 最初は最小台数 1 台で開始可能で、需要に合わせてノードを追加するだけで拡張。
- ゲートウェイ層のノード情報を更新すればよく、クライアント側の変更は最小限です。

### (4) 異なる環境を混在させた構成も可能
- **Linux/Windows やオンプレ/クラウドを混在させたハイブリッド構成にも動的に対応可能** であり、これがこのシステムの大きな特徴です。
- 既存 GPU 資産を活かしつつ、必要に応じてクラウド GPU を追加や他の機能への付け替えする運用が容易です。

### (5) 運用の容易性
- **フロントエンドにはVercelを利用。Tailscaleを応用したVPN＋リバースプロキシ構成により、個別サーバーのポート開放管理が不要**。
- 一時的にノードを外す／戻すといった制御や、ログ・メトリクスの集約がゲートウェイ層で完結。

### (6) コストと性能のバランスを取りやすい
- **ハイエンドとミドルレンジ GPU を混在させ、ジョブ適材適所を図れます。**
- 「常に最上位 GPU だけを大量に用意する」必要がなく、コスト最適化が可能。

## 3. 想定ユースケース

### (1) 高度な画像・動画生成サービス
- 様々なアプリケ－ションからジョブを受け付け、バックエンドで複数 GPU ノードに最適に展開。
- キャンペーン時のみノードを増設してスパイクに対応する、といった運用が極めて容易。

### (2) 社内向け LLM 推論基盤
- 社内ツール群が共通 LLM API を利用し、用途に応じて高速モデル/高精度モデルを切り替え。

### (3) バッチ系 CGレンダリング / シミュレーションで特に有用
- ジョブキューとして多数のリクエストを同時に受け付け、GPU クラスターで順次処理。
- 実行ノードの管理を基盤側に隠蔽できます。

## 4. 導入・拡張のしやすさ

- **段階的導入**: 既存単一 GPU サービスの前にゲートウェイを挟む所から始め、徐々にノード追加が出来ます。
- **既存コード再利用**: 既存のHTTP API 互換を維持し、フロント実装の大幅変更を回避。
- **自動スケール**: 手動でノード増減がベースですが、クラウドのオートスケールと統合するシステムにもカスタム開発で展開可能です。

## 5. まとめ

本システムは ComfyUI のスケールのためのシステム用途での開発から始まりましたが、システムの拡張・最適化を通じて **高度なGPU を多数用いる生成 AI / CG アプリのための汎用基盤** として機能可能に進化しました。利用者には安定した単一サービスとして見せつつ、裏側では複数 GPU を柔軟に増減できるため、プロダクト開発側は機能実装に集中できます。

**オンプレとクラウド、OS の違いを超えて GPU リソースを束ねられるため、既存資産を活かしながら段階的に AI インフラを強化する土台として活用できます。**
